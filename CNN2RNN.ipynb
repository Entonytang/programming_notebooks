{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import librosa \n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(78000,) 16000 (74000,) 16000\n"
     ]
    }
   ],
   "source": [
    "files = librosa.util.find_files(\"pcsnpny-20150204-mkj/wav\")\n",
    "file = files[0]\n",
    "sig1, sr1 = librosa.core.load(file, sr=None)\n",
    "sig2, sr2 = librosa.core.load(files[1], sr=None)\n",
    "print(sig1.shape, sr1, sig2.shape, sr2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 78000])\n",
      "input size: torch.Size([1, 1, 78000])\n",
      "conv1d out: torch.Size([1, 66, 242])\n",
      "conv2d out: torch.Size([1, 64, 64, 240])\n",
      "gru in: torch.Size([1, 240, 4096])\n",
      "gru out: torch.Size([1, 240, 1024])\n",
      "dense in: torch.Size([240, 1024])\n",
      "torch.Size([1, 240])\n",
      "input size: torch.Size([1, 1, 74000])\n",
      "conv1d out: torch.Size([1, 66, 230])\n",
      "conv2d out: torch.Size([1, 64, 64, 228])\n",
      "gru in: torch.Size([1, 228, 4096])\n",
      "gru out: torch.Size([1, 228, 1024])\n",
      "dense in: torch.Size([228, 1024])\n",
      "torch.Size([1, 228])\n"
     ]
    }
   ],
   "source": [
    "class CNN2RNN(nn.Module):\n",
    "    def __init__(self, conv_in_channels, conv_out_features, ws, hs, rnn_hidden_size, rnn_output_size):\n",
    "        super(CNN2RNN, self).__init__()\n",
    "        self.cin_channels = conv_in_channels\n",
    "        self.cout_features = conv_out_features\n",
    "        self.rnn_hid = rnn_hidden_size\n",
    "        self.rnn_out = rnn_output_size\n",
    "        \n",
    "        \n",
    "        # hard coding vars so I know what they are.\n",
    "        n_layers = 2 # number of layers of RNN\n",
    "        batch_size = 1\n",
    "        kernel2d = 3\n",
    "        # hidden initialization\n",
    "        self.hidden = self.init_hidden(n_layers, batch_size, rnn_hidden_size)\n",
    "        \n",
    "        # net layer types\n",
    "        self.c1 = nn.Conv1d(conv_in_channels, conv_out_features+kernel2d-1, ws, stride=hs)\n",
    "        self.c2 = nn.Conv2d(1, conv_out_features, kernel2d)\n",
    "        self.gru = nn.GRU(conv_out_features*conv_out_features, rnn_hidden_size, n_layers, \n",
    "                          batch_first=True, bidirectional=False)\n",
    "        self.dense = nn.Linear(rnn_hidden_size, 1)\n",
    "        \n",
    "    def forward(self, input):\n",
    "        print(\"input size: {}\".format(input.size()))\n",
    "        conv_out = self.c1(input)\n",
    "        print(\"conv1d out: {}\".format(conv_out.size()))\n",
    "        conv2_out = self.c2(conv_out.unsqueeze(0))\n",
    "        print(\"conv2d out: {}\".format(conv2_out.size()))\n",
    "        gru_in = conv2_out.view(input.size(0), -1, self.cout_features * self.cout_features)\n",
    "        print(\"gru in: {}\".format(gru_in.size()))\n",
    "        gru_out, self.hidden = self.gru(gru_in, self.hidden)\n",
    "        print(\"gru out: {}\".format(gru_out.size()))\n",
    "        dense_in = gru_out.view(gru_in.size(1)*input.size(0) ,-1)\n",
    "        print(\"dense in: {}\".format(dense_in.size()))\n",
    "        out_space = self.dense(dense_in)\n",
    "        out = F.sigmoid(out_space)\n",
    "        out = out.view(input.size(0), -1)\n",
    "        return(out)\n",
    "        \n",
    "    def init_hidden(self, nl, bat_dim, hid_dim):\n",
    "        # The axes: (num_layers, minibatch_size, hidden_dim)\n",
    "        # see docs\n",
    "        return (Variable(torch.zeros(nl, bat_dim, hid_dim)))\n",
    "\n",
    "ws=640\n",
    "hs=ws//2\n",
    "nb=64\n",
    "\n",
    "net = CNN2RNN(1, nb, ws, hs, 1024, 2)\n",
    "inputs1 = torch.Tensor(sig1)\n",
    "inputs1.unsqueeze_(0)\n",
    "inputs1.unsqueeze_(0)\n",
    "print(net(Variable(inputs1)).size())\n",
    "inputs2 = torch.Tensor(sig2)\n",
    "inputs2.unsqueeze_(0)\n",
    "inputs2.unsqueeze_(0)\n",
    "print(net(Variable(inputs2)).size())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "torch"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
